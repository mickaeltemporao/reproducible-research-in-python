{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reproducible-research-in-python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z89XnYAW4FMf",
        "colab_type": "text"
      },
      "source": [
        "# Data Modeling\n",
        "\n",
        "This notebook was created as part of a workshop on *Reproducible Research in Python*. \n",
        "\n",
        "- You can access the entire workshop materials at: [Reproducible Research in Python](https://github.com/mickaeltemporao/reproducible-research-in-python).\n",
        "\n",
        "**Learning Objective:** \n",
        "- Learn create data pre-processing functions\n",
        "- Learn how to train and save model objects\n",
        "- Learn to load and make predictions on unseen data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5-fiCoZXn7x",
        "colab_type": "text"
      },
      "source": [
        "## Preparing the training set\n",
        "\n",
        "Let's try to forecast the election based on existing polls!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc1rqhS9dRQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Installing and Importing Packages\n",
        "!pip install wikipedia\n",
        "import wikipedia as wp \n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8ZQeV6O_w6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For the training part we will rely on polls from the 2015 election.\n",
        "page_titles = [\n",
        "    \"Opinion polling for the 2015 Canadian federal election\",\n",
        "    \"Opinion polling for the 2019 Canadian federal election\",\n",
        "]\n",
        "\n",
        "html_pages = [wp.page(page).html().encode(\"UTF-8\") for page in page_titles]\n",
        "dfs = [pd.read_html(html)[0] for html in html_pages]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NhH4KDc_1S0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cleaning the training set.\n",
        "import re\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv2mh4kc_2Am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function to fix the column names\n",
        "\n",
        "names_dict = {\n",
        "    \"polling_firm\": \"source\",\n",
        "    \"last_dateof_polling\": \"date\",\n",
        "    \"samplesize\": \"sample_size\",\n",
        "    \"marginof_error\": \"error\",\n",
        "    \"cons\": \"cpc\",\n",
        "    \"liberal\": \"lpc\",\n",
        "    \"green\": \"gpc\",\n",
        "    \"polling_method\": \"method\",\n",
        "}\n",
        "\n",
        "def fix_names(input_df, names_dict):\n",
        "    \"\"\"Renames the columns in the input dataframe.\"\"\"\n",
        "    regex = \"[a-z]+\"\n",
        "\n",
        "    columnn_names = []\n",
        "\n",
        "    tmp_df = input_df.copy()\n",
        "\n",
        "    for c in tmp_df.columns:\n",
        "        tmp = c.lower()\n",
        "        columnn_names.append(tmp.replace(\" \", \"_\"))\n",
        "\n",
        "    tmp_names = [\"_\".join(re.findall(regex, i)) for i in columnn_names]\n",
        "    tmp_df.columns = tmp_names\n",
        "\n",
        "    return tmp_df.rename(columns=names_dict)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ_C-bxH_2-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's edit them...\n",
        "df_train = fix_names(df_train, names_dict)\n",
        "df_train.columns\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs5-LfEo_3mt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's keep relevant variables only\n",
        "\n",
        "to_keep = [\n",
        "    'source',\n",
        "    'date',\n",
        "    'lpc',\n",
        "    'cpc',\n",
        "    'ndp',\n",
        "    'bq',\n",
        "    'gpc',\n",
        "    'method'\n",
        "]\n",
        "\n",
        "df_train = df_train[to_keep]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDrGHYm8_4mg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What does the training set look like ?\n",
        "df_train = df_train[to_keep]\n",
        "df_train.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v16hmGjF_5DN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's store and remove the election results\n",
        "results_2015 = df_train.iloc[1]\n",
        "df_train = df_train.drop(1).dropna()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRKATV5V_5hG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's deal with missing values\n",
        "df_train.dropna(inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7KfKMpj_5_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What about the data types?\n",
        "df_train.select_dtypes(include='object')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb9EL1Ab_6bM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's fix that date variable\n",
        "df_train['date'] = pd.to_datetime(df_train.date)\n",
        "df_train.sample(3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3jFedUS_66O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# As we mentioned, most algorithms require the data to be in long-format\n",
        "parties = [\"lpc\", \"cpc\", \"ndp\", \"bq\", \"gpc\"]\n",
        "\n",
        "df_train = pd.melt(\n",
        "    df_train.reset_index(),\n",
        "    id_vars=['date', 'source', 'method'],\n",
        "    value_vars=parties,\n",
        "    var_name='party',\n",
        "    value_name='share',\n",
        ")\n",
        "\n",
        "df_train.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JIVTlFk_7nW",
        "colab_type": "text"
      },
      "source": [
        "Let's do some more exploration and see if polls actually improve as we get closer to the election day?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiGE5ZRD_8db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We need to merge the outcome of the election back\n",
        "targets = (\n",
        "    results_2015\n",
        "    .transpose()\n",
        "    .iloc[2:-1]\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "targets.columns = ['party', 'outcome']\n",
        "targets['outcome'] = targets.outcome.astype('float')\n",
        "\n",
        "df_train = df_train.merge(targets)\n",
        "df_train.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0kr_VCd__Mj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Does time have an impact on the error of pollsters?\n",
        "df_train['error'] = abs(df_train.share - df_train.outcome)\n",
        "df_train.set_index('date', inplace=True)\n",
        "df_train.error.resample('D').mean().plot()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj-PEYSf__yk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What about the data collection method?\n",
        "df_train.method.value_counts()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEB2FwS2AANM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's use some regex to do an initial cleaning\n",
        "regex = r\"\\(.*\\)|/| |rolling\"\n",
        "df_train['method'] = df_train.method.str.replace(regex, \"\")\n",
        "df_train['method'].value_counts()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lYfd3naAAsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's groups these even further\n",
        "df_train['method'] = df_train.method.str.lower().str[:3]\n",
        "df_train['method'].value_counts()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol0xixb0ABGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's use seaborn this time as we now have a long-dataset and see see if there is an abservable difference between the data collection methods\n",
        "import seaborn as sns\n",
        "sns.violinplot(x=\"method\", y=\"error\",\n",
        "               split=True, inner=\"quart\",\n",
        "               data=df_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBcf3YkBAi7-",
        "colab_type": "text"
      },
      "source": [
        "## Preparing the test set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5OTq9IVeQCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now that we have some intuition about 2015!\n",
        "# We need to prepare our test set and verify it has the same form as the train set.\n",
        "df = pd.read_csv(\"national_polls_2019.csv\", parse_dates=['date'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iStY4A9vZvvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = new_df.stack()\n",
        "df_test.name = 'share'\n",
        "df_test = df_test.reset_index().set_index('date')\n",
        "\n",
        "data_2019 = {\n",
        "    \"party\": [\"lpc\", \"cpc\", \"bq\", \"ndp\", \"gpc\"],\n",
        "    \"outcome\": [33.1,34.4, 7.7, 15.9, 6.5],\n",
        "}\n",
        "\n",
        "df_test = df_test.reset_index().merge(pd.DataFrame(data_2019)).set_index('date')\n",
        "df_test['error'] = abs(df_test.share - df_test.outcome)\n",
        "all(df_test.columns == df_train.columns)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WyU3xaeAo5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's create a function to clean the method string!\n",
        "def str_magic(input_series):\n",
        "    regex = r\"\\(.*\\)|/| |rolling\"\n",
        "    tmp = input_series.copy()\n",
        "    tmp = df_test['method'].copy()\n",
        "    tmp = tmp.str.replace(regex, \"\")\n",
        "    return tmp.str.lower().str[:3]\n",
        "\n",
        "df_test['method'] = str_magic(df_test['method'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CZmdmSLApqn",
        "colab_type": "text"
      },
      "source": [
        "## Feature Creation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdyAlJbqAqSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We need to prepare our features\n",
        "election_day_2015 = \"2015-10-19\"\n",
        "election_day_2019 = \"2019-10-21\"\n",
        "\n",
        "def add_days(df, election_day):\n",
        "    test = pd.to_datetime(election_day) - df.reset_index()['date']\n",
        "    test.index = df.index\n",
        "    df['days'] = test.dt.days\n",
        "    return df\n",
        "\n",
        "df_train = add_days(df_train, election_day_2015)\n",
        "df_test = add_days(df_test, election_day_2019)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o7s1JInAsUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One-Hot Encoding\n",
        "# Let's remove the group with most counts\n",
        "df_train.method.value_counts().plot(kind='barh')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRqJ8jjKAvyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's drop the most common value\n",
        "train_dummies = pd.get_dummies(df_train['method'])\n",
        "train_dummies.pop('tel')\n",
        "df_train = pd.concat([df_train, train_dummies], axis=1)\n",
        "\n",
        "test_dummies = pd.get_dummies(df_test['method'])\n",
        "test_dummies.pop('tel')\n",
        "df_test = pd.concat([df_test, test_dummies], axis=1)\n",
        "\n",
        "y_var = 'outcome'\n",
        "X_vars = ['share', 'days', 'ivr', 'onl']\n",
        "\n",
        "predictions = []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcYoW4ela5aD",
        "colab_type": "text"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X55Thbzfez4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now that we have our train and test sets let's train our models\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import pickle\n",
        "\n",
        "models = [\n",
        "    LinearRegression(),\n",
        "    RandomForestRegressor(),\n",
        "]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XFmeOf1AwyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit, predict, and save your models\n",
        "for i in range(2):\n",
        "    models[i].fit(df_train[X_vars], df_train[y_var])\n",
        "    predictions.append(models[i].predict(df_test[X_vars]))\n",
        "    pickle.dump(models[i], open(f\"model_{i}.pkl\", 'wb'))\n",
        "\n",
        "predictions[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0LPvyXjAykO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load a saved model from disc and make a prediction\n",
        "input_date = '2019-09-20'\n",
        "\n",
        "file_name = \"model_0.pkl\"\n",
        "loaded_model = pickle.load(open(file_name, 'rb'))\n",
        "\n",
        "predictions = loaded_model.predict(df_test.loc[input_date,X_vars])\n",
        "results = df_test.loc[input_date, [y_var] + [\"party\", \"share\"]].assign(model_0=predictions)\n",
        "results['abs_e_poll'] = abs(results.outcome - results.share)\n",
        "results['abs_e_model_0'] = abs(results.outcome - results.model_0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeSL6vogggoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Did our model beat the polls? \n",
        "print(results.loc[:,results.columns.str.contains('abs_e')].sum())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6b5lNangXTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bonus - Packaging\n",
        "## > Let's go to your terminal!"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}