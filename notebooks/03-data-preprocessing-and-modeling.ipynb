{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reproducible-research-in-python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z89XnYAW4FMf",
        "colab_type": "text"
      },
      "source": [
        "# Data Modeling\n",
        "\n",
        "This notebook was created as part of a workshop on *Reproducible Research in Python*. \n",
        "\n",
        "- You can access the entire workshop materials at: [Reproducible Research in Python](https://github.com/mickaeltemporao/reproducible-research-in-python).\n",
        "\n",
        "**Learning Objective:** \n",
        "- Learn create data pre-processing functions\n",
        "- Learn how to train and save model objects\n",
        "- Learn to load and make predictions on unseen data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5-fiCoZXn7x",
        "colab_type": "text"
      },
      "source": [
        "## Data Acquisition & Cleaning\n",
        "\n",
        "Let's try to forecast the election based on existing polls!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc1rqhS9dRQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Installing and Importing Packages\n",
        "!pip install wikipedia\n",
        "import wikipedia as wp \n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8ZQeV6O_w6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's gather the Data\n",
        "# For the training set we will rely on polls from the 2015 election.\n",
        "# For the test set we will rely on polls from the 2019 election.\n",
        "page_titles = [\n",
        "    \"Opinion polling for the 2015 Canadian federal election\",\n",
        "    \"Opinion polling for the 2019 Canadian federal election\",\n",
        "]\n",
        "\n",
        "html_pages = [wp.page(page).html().encode(\"UTF-8\") for page in page_titles]\n",
        "dfs = [pd.read_html(html)[0] for html in html_pages]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfd9onO4exHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a function to rename the column names\n",
        "import re\n",
        "\n",
        "names_dict = {\n",
        "    \"polling_firm\": \"source\",\n",
        "    \"last_dateof_polling\": \"date\",\n",
        "    \"samplesize\": \"sample_size\",\n",
        "    \"marginof_error\": \"error\",\n",
        "    \"cons\": \"cpc\",\n",
        "    \"liberal\": \"lpc\",\n",
        "    \"green\": \"gpc\",\n",
        "    \"polling_method\": \"method\",\n",
        "}\n",
        "\n",
        "def fix_names(input_df, names_dict):\n",
        "    \"\"\"Renames the columns in the input dataframe.\"\"\"\n",
        "    regex = \"[a-z]+\"\n",
        "\n",
        "    columnn_names = []\n",
        "    tmp_df = input_df.copy()\n",
        "\n",
        "    # Fix double header \n",
        "    if type(tmp_df.columns[0]) is tuple:\n",
        "        tmp_cols = [col[0] for col in tmp_df.columns]\n",
        "        tmp_df.columns = tmp_cols\n",
        "\n",
        "    for c in tmp_df.columns:\n",
        "        tmp = c.lower()\n",
        "        columnn_names.append(tmp.replace(\" \", \"_\"))\n",
        "\n",
        "    tmp_names = [\"_\".join(re.findall(regex, i)) for i in columnn_names]\n",
        "    tmp_df.columns = tmp_names\n",
        "\n",
        "    return tmp_df.rename(columns=names_dict)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ_C-bxH_2-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Edit the columns names in both data frames\n",
        "dfs = [fix_names(df, names_dict) for df in dfs]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs5-LfEo_3mt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Subsets variables and merge the data into a single dataframe\n",
        "# This will help us to prepare our train/test set later on so that both \n",
        "# sets have the same form.\n",
        "\n",
        "to_keep = [\n",
        "    'source',\n",
        "    'date',\n",
        "    'lpc',\n",
        "    'cpc',\n",
        "    'ndp',\n",
        "    'bq',\n",
        "    'gpc',\n",
        "    'method'\n",
        "]\n",
        "\n",
        "dfs = [df[to_keep] for df in dfs]\n",
        "df = pd.concat(dfs)\n",
        "df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v16hmGjF_5DN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# As we mentioned, most algorithms require the data to be in long-format\n",
        "parties = [\"lpc\", \"cpc\", \"ndp\", \"bq\", \"gpc\"]\n",
        "\n",
        "df = pd.melt(\n",
        "    df,\n",
        "    id_vars=['date', 'source', 'method'],\n",
        "    var_name='party',\n",
        "    value_name='share',\n",
        ")\n",
        "df.source.value_counts()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fYKzelMnt2-",
        "colab_type": "text"
      },
      "source": [
        "This is still not a long data frame as our share variable contains the vote share predicted by the polls and our target variable (the election outcome).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvpzC3gutSze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add the target variable \n",
        "# We need a year to merge the target on\n",
        "df['date'] = pd.to_datetime(df.date)\n",
        "df['year'] = df.date.dt.year\n",
        "mask = df['source'] == 'Election'\n",
        "targets_df = df.loc[mask].rename(columns={'share':'target'})\n",
        "\n",
        "df.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-PWhp67tjA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can now merge the target into the original dataframe\n",
        "df = df.merge(\n",
        "    targets_df[['year', 'party', 'target']], \n",
        "    how='left', \n",
        "    on=['year', 'party']\n",
        ")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlo_xJGRkgIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# And remove observations that are the target we are trying to forecast \n",
        "df = df.loc[~mask]\n",
        "df.sample(5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRKATV5V_5hG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's deal with missing values\n",
        "df = df.dropna()\n",
        "df.sample(5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7KfKMpj_5_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Are the data types correct?\n",
        "df.dtypes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGZBgSIgw36O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's look at remaining objects\n",
        "df.select_dtypes(include='object')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JIVTlFk_7nW",
        "colab_type": "text"
      },
      "source": [
        "Ok, we now have a long data set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBcf3YkBAi7-",
        "colab_type": "text"
      },
      "source": [
        "## Modeling Data Exploration \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOJmUESex3yy",
        "colab_type": "text"
      },
      "source": [
        "Let's do some more exploration to see if the polls actually improve as we get closer to the election day?\n",
        "\n",
        "If we want to further explore the data with the objective of building intuition around the model and the features we want to build, we need to focus only on the training set. This allows us to simulate a real world situation where we are only using information that is available at the time of the prediction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwj6jKkJxpQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will create a mask to separate the training set from the test set.\n",
        "df.set_index('date', inplace=True)\n",
        "training_mask = df.year < 2019"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0kr_VCd__Mj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now let's see if time seems to be related to the error of the pollsters?\n",
        "# Let's measure the size of the error made by the pollsters.\n",
        "df['error'] = abs(df.share - df.target)\n",
        "df.loc[training_mask].error.resample('D').mean().plot()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj-PEYSf__yk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What about the data collection method?\n",
        "df.loc[training_mask].method.value_counts()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEB2FwS2AANM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's define a function to do some initial cleaning\n",
        "def str_magic(input_series):\n",
        "    return input_series.str.lower().str[:3]\n",
        "\n",
        "df['method'] = str_magic(df['method'])\n",
        "df['method'].value_counts()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol0xixb0ABGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's use seaborn this time as we now have a long-dataset and see see if there is an abservable difference between the data collection methods\n",
        "import seaborn as sns\n",
        "sns.violinplot(x=\"method\", y=\"error\",\n",
        "               split=True, inner=\"quart\",\n",
        "               data=df.loc[training_mask])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CZmdmSLApqn",
        "colab_type": "text"
      },
      "source": [
        "## Feature Creation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5OTq9IVeQCl",
        "colab_type": "text"
      },
      "source": [
        "Now that we have some intuition about 2015, let's add new features to the data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdyAlJbqAqSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We need to prepare our features\n",
        "# Let's add the number of days until the election\n",
        "election_day_2015 = \"2015-10-19\"\n",
        "election_day_2019 = \"2019-10-21\"\n",
        "\n",
        "def count_days(df, election_day):\n",
        "    output = pd.to_datetime(election_day) - df.reset_index()['date']\n",
        "    output.index = df.index\n",
        "    return output.dt.days\n",
        "\n",
        "df.loc[training_mask, 'days'] = count_days(df.loc[training_mask], election_day_2015)\n",
        "df.loc[~training_mask, 'days'] = count_days(df.loc[~training_mask], election_day_2019)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o7s1JInAsUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One-Hot Encoding\n",
        "# Let's remove the group with most counts\n",
        "df.loc[training_mask, 'method'].value_counts().plot(kind='barh')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRqJ8jjKAvyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's drop the most common value\n",
        "dummies = pd.get_dummies(df['method'])\n",
        "dummies.pop('tel')\n",
        "df = pd.concat([df, dummies], axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRmlJgb_5SM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finally, separate the training set from the test set.\n",
        "df_train = df.loc[training_mask].copy()\n",
        "df_test = df.loc[~training_mask].copy()\n",
        "\n",
        "# And define our model.\n",
        "y_var = 'target'\n",
        "X_vars = ['share', 'days', 'ivr', 'onl']\n",
        "\n",
        "predictions = []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcYoW4ela5aD",
        "colab_type": "text"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X55Thbzfez4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now that we have our train and test sets let's train our models\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import pickle\n",
        "\n",
        "models = [\n",
        "    LinearRegression(),\n",
        "    RandomForestRegressor(),\n",
        "]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XFmeOf1AwyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit, predict, and save your models\n",
        "for i in range(2):\n",
        "    models[i].fit(df_train[X_vars], df_train[y_var])\n",
        "    predictions.append(models[i].predict(df_test[X_vars]))\n",
        "    pickle.dump(models[i], open(f\"model_{i}.pkl\", 'wb'))\n",
        "\n",
        "predictions[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0LPvyXjAykO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load a saved model from disc and make a prediction\n",
        "input_date = '2019-09-20'\n",
        "\n",
        "file_name = \"model_0.pkl\"\n",
        "loaded_model = pickle.load(open(file_name, 'rb'))\n",
        "\n",
        "predictions = loaded_model.predict(df_test.loc[input_date,X_vars])\n",
        "results = df_test.loc[input_date, [y_var] + [\"party\", \"share\"]].assign(model_0=predictions)\n",
        "results['abs_e_poll'] = abs(results.target - results.share)\n",
        "results['abs_e_model_0'] = abs(results.target - results.model_0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeSL6vogggoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Did our model beat the polls? \n",
        "print(results.loc[:,results.columns.str.contains('abs_e')].sum())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6b5lNangXTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bonus - Packaging\n",
        "## > Let's go to your terminal!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2-xXTrJ5_zX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}